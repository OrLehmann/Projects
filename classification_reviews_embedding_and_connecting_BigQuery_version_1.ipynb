{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OrLehmann/Projects/blob/main/classification_reviews_embedding_and_connecting_BigQuery_version_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsB7TCh6zAHL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "from google.oauth2 import service_account\n",
        "import openai\n",
        "import numpy as np\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to your API key file\n",
        "api_key_file = '/content/drive/MyDrive/openai_api_key.txt'  # Adjust the path if necessary\n",
        "\n",
        "# Read the API key from the file\n",
        "with open(api_key_file, 'r') as file:\n",
        "    api_key = file.read().strip()\n",
        "\n",
        "# Set the environment variable\n",
        "os.environ['OPENAI_API_KEY'] = api_key\n",
        "\n",
        "# Optional: Verify that the environment variable is set\n",
        "print(\"API Key Loaded:\", os.environ.get('OPENAI_API_KEY') is not None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JOfcY1hzKvC",
        "outputId": "38e798ee-b611-4c41-fd84-fab56f33650b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "API Key Loaded: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to your BigQuery service account key file\n",
        "service_account_path = '/content/drive/MyDrive/bigquery_service_account.json'  # Update with the correct path\n",
        "\n",
        "# Authenticate with BigQuery\n",
        "credentials = service_account.Credentials.from_service_account_file(service_account_path)\n",
        "client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n"
      ],
      "metadata": {
        "id": "SQcJje_WzNAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset and table information\n",
        "PROJECT_ID = credentials.project_id\n",
        "DATASET_ID = \"hotel_feedback\"\n",
        "TABLE_ID = \"classified_reviews\""
      ],
      "metadata": {
        "id": "voXoAGgLzULp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Excel file\n",
        "file_path = \"/content/drive/My Drive/Caesar eilat unclassified reviews.csv\"\n",
        "df = pd.read_csv(file_path, usecols=[\"ID\",\"feedback\", \"Site\", \"Month\", \"Rating\", \"Pos=1/Neg=0\"])\n",
        "df.rename(columns={\"Pos=1/Neg=0\": \"Pos_Neg\"}, inplace=True)\n",
        "df[\"Month\"] = df[\"Month\"].astype(str)  # Convert month to string\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vQI4z8RozWmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up OpenAI API key\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "rnBbjs6X1KZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Department categories\n",
        "departments = [\n",
        "    \"Front Desk\", \"Food and Beverages\", \"Executive Chef\", \"Food and Beverage Auditor\",\n",
        "    \"Housekeeping\", \"Security\", \"Accountant\", \"Entertainment and Activities\",\n",
        "    \"Procurement\", \"Pool\", \"Reservations\", \"Groups and Public Relations\",\n",
        "    \"Human Resources and Stewards\", \"Maintenance\", \"Guest Service Center\",\n",
        "    \"Evening Manager\", \"General Manager\", \"Feedback with names\"\n",
        "]"
      ],
      "metadata": {
        "id": "ILb2qQL91LOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute embeddings for department names using \"text-embedding-3-large\"\n",
        "\n",
        "def get_embeddings(texts):\n",
        "    response = openai.embeddings.create(\n",
        "        input=texts,  # Send a batch of texts\n",
        "        model=\"text-embedding-3-large\"\n",
        "    )\n",
        "    return [np.array(e.embedding) for e in response.data]\n",
        "\n",
        "# Compute department embeddings in a batch\n",
        "department_embeddings = np.array(get_embeddings(departments))\n",
        "\n",
        "# Function to classify reviews using embeddings\n",
        "def classify_reviews_with_embedding(reviews):\n",
        "    \"\"\"Classifies multiple reviews using embedding similarity with text-embedding-3-large.\"\"\"\n",
        "    review_embeddings = get_embeddings(reviews)  # Get embeddings in batch\n",
        "    classified_results = []\n",
        "    for review_embedding in review_embeddings:\n",
        "        similarities = np.dot(department_embeddings, review_embedding)  # Cosine similarity approximation\n",
        "        top_indices = np.where(similarities > 0.3)[0]  # Thresholding instead of fixed top-2\n",
        "        if len(top_indices) == 0:\n",
        "            top_indices = [np.argmax(similarities)]  # Ensure at least 1 category\n",
        "        classified_results.append([departments[i] for i in top_indices])\n",
        "    return classified_results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HZHOiR231UPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify reviews in batch\n",
        "batch_size = 35  # Adjust batch size as needed\n",
        "reviews_list = df[\"feedback\"].tolist()\n",
        "categories_list = []\n",
        "\n",
        "for i in range(0, len(reviews_list), batch_size):\n",
        "    batch_reviews = reviews_list[i:i+batch_size]\n",
        "    batch_categories = classify_reviews_with_embedding(batch_reviews)\n",
        "    categories_list.extend(batch_categories)\n",
        "\n",
        "df[\"categories\"] = categories_list\n",
        "\n",
        "# Ensure 'categories' is always a list (important for BigQuery)\n",
        "df[\"categories\"] = df[\"categories\"].apply(lambda x: x if isinstance(x, list) else [x])\n",
        "\n",
        "\n",
        "# Convert dataframe to JSON records\n",
        "json_data = df.to_dict(orient=\"records\")\n",
        "output_json_path = \"classified_reviews.json\"\n",
        "# Write NDJSON format (each JSON object on a new line)\n",
        "with open(output_json_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for record in json_data:\n",
        "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "print(f\"✅ JSON file saved at: {output_json_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6g1FOgT1XFO",
        "outputId": "5ec51eb2-2289-4e69-a8cf-f65aab3ab6b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ JSON file saved at: classified_reviews.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define BigQuery Schema\n",
        "schema = [\n",
        "    bigquery.SchemaField(\"ID\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"feedback\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"Site\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"Month\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"Rating\", \"INTEGER\"),\n",
        "    bigquery.SchemaField(\"Pos_Neg\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"categories\", \"STRING\", mode=\"REPEATED\")\n",
        "]\n",
        "\n",
        "# Ensure dataset exists\n",
        "dataset_ref = client.dataset(DATASET_ID)\n",
        "dataset = bigquery.Dataset(dataset_ref)\n",
        "dataset.location = \"US\"\n",
        "try:\n",
        "    client.create_dataset(dataset)\n",
        "    print(f\"Dataset {DATASET_ID} created.\")\n",
        "except Exception:\n",
        "    print(f\"Dataset {DATASET_ID} already exists.\")\n",
        "\n",
        "# Ensure table exists\n",
        "table_ref = dataset_ref.table(TABLE_ID)\n",
        "table = bigquery.Table(table_ref, schema=schema)\n",
        "try:\n",
        "    client.create_table(table)\n",
        "    print(f\"Table {TABLE_ID} created.\")\n",
        "except Exception:\n",
        "    print(f\"Table {TABLE_ID} already exists.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyd1woId1f2A",
        "outputId": "61f16d1f-e0ca-4645-d933-b4ae0a343685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset hotel_feedback already exists.\n",
            "Table classified_reviews already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load JSON data into BigQuery\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    schema=schema,\n",
        "    source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
        "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
        "    autodetect=False\n",
        ")\n",
        "\n",
        "# Validate JSON file before uploading\n",
        "with open(output_json_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        try:\n",
        "            json.loads(line)  # Ensure each line is a valid JSON object\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Invalid JSON line: {line}\")\n",
        "            print(e)\n",
        "\n",
        "# Upload JSON to BigQuery\n",
        "with open(output_json_path, \"rb\") as json_file:\n",
        "    job = client.load_table_from_file(json_file, table_ref, job_config=job_config)\n",
        "    job.result()  # Wait for completion\n",
        "\n",
        "\n",
        "print(f\"✅ Data uploaded to BigQuery: {PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG2pH-PG1iRa",
        "outputId": "44e9fe22-c050-42d4-c877-8ef90e7e8aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data uploaded to BigQuery: gifted-proxy-452616-s7.hotel_feedback.classified_reviews\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Define the path for the new JSON file\n",
        "classified_reviews_output_path = \"/content/drive/MyDrive/classified_reviews_export.json\"\n",
        "\n",
        "# Convert dataframe to JSON records\n",
        "classified_reviews_json = df.to_dict(orient=\"records\")\n",
        "\n",
        "# Write final classified reviews JSON\n",
        "with open(classified_reviews_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(f\"✅ Classified reviews exported to: {classified_reviews_output_path}\")"
      ],
      "metadata": {
        "id": "0vP2rtqeuy63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba38a378-1cc0-4d58-ac4f-18ff742b9ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Classified reviews exported to: /content/drive/MyDrive/classified_reviews_export.json\n"
          ]
        }
      ]
    }
  ]
}